{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepatation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import os.path\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "import json\n",
    "from config import CLIENT_ID, CLIENT_SECRET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sheets(sheets):\n",
    "    '''\n",
    "    Get rid of the duplicate sheets\n",
    "    Only take the sheets from the latest point in the day\n",
    "    '''\n",
    "    \n",
    "    new_ranges = []\n",
    "    for s in sheets:\n",
    "        new_ranges.append(s.get(\"properties\", {}).get(\"title\"))\n",
    "        \n",
    "    clean_new_ranges = new_ranges.copy()\n",
    "    for i, x in enumerate(clean_new_ranges):\n",
    "        clean_new_ranges[i] = x.split('_')[0]\n",
    "\n",
    "    indices = []\n",
    "    for item in set(clean_new_ranges):\n",
    "        indices.append(clean_new_ranges.index(item))\n",
    "\n",
    "    clean_new_ranges = []\n",
    "    for index in sorted(indices):\n",
    "        clean_new_ranges.append(new_ranges[index])\n",
    "\n",
    "    return clean_new_ranges\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If modifying these scopes, delete the file token.pickle.\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "\n",
    "# The ID and range of a sample spreadsheet.\n",
    "SAMPLE_SPREADSHEET_ID = '1yZv9w9zRKwrGTaR-YzmAqMefw4wMlaXocejdxZaTs6w'\n",
    "\n",
    "\"\"\"Shows basic usage of the Sheets API.\n",
    "Prints values from a sample spreadsheet.\n",
    "\"\"\"\n",
    "creds = None\n",
    "# The file token.pickle stores the user's access and refresh tokens, and is\n",
    "# created automatically when the authorization flow completes for the first\n",
    "# time.\n",
    "if os.path.exists('token.pickle'):\n",
    "    with open('token.pickle', 'rb') as token:\n",
    "        creds = pickle.load(token)\n",
    "# If there are no (valid) credentials available, let the user log in.\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "            'credentials.json', SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    # Save the credentials for the next run\n",
    "    with open('token.pickle', 'wb') as token:\n",
    "        pickle.dump(creds, token)\n",
    "\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "#get all the sheet names for ranges when querying\n",
    "sheet_metadata = service.spreadsheets().get(spreadsheetId=SAMPLE_SPREADSHEET_ID).execute()\n",
    "sheets = sheet_metadata.get('sheets', '')\n",
    "\n",
    "cleaned_ranges = clean_sheets(sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now that we have the sheet names cleaned\n",
    "we can now start doing some extractions\n",
    "'''\n",
    "def get_col_names():\n",
    "    col_names= []\n",
    "    for sheet_range in cleaned_ranges:\n",
    "        # Call the Sheets API\n",
    "        sheet = service.spreadsheets()\n",
    "        result = sheet.values().get(spreadsheetId=SAMPLE_SPREADSHEET_ID,\n",
    "                                    range=sheet_range).execute()\n",
    "        values = result.get('values', [])      \n",
    "        for col in values[0]:\n",
    "            col_names.append(col[:])\n",
    "    return set(col_names)\n",
    "\n",
    "cols = get_col_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jan29_230pm\n",
      "Jan28_11pm\n",
      "Jan27_830pm\n",
      "Jan26_11pm\n",
      "Jan25_10pm\n",
      "Jan24_12pm\n",
      "Jan23_12pm\n",
      "Jan22_12pm\n"
     ]
    }
   ],
   "source": [
    "def get_data(sheet_range):\n",
    "    tmp_df = pd.DataFrame([])\n",
    "    sheet = service.spreadsheets()\n",
    "    result = sheet.values().get(spreadsheetId=SAMPLE_SPREADSHEET_ID,\n",
    "                                range=sheet_range).execute()\n",
    "\n",
    "    header = result.get('values', [])[0]   # Assumes first line is header!\n",
    "    values = result.get('values', [])[1:]  # Everything else is data.\n",
    "    \n",
    "    '''\n",
    "    rows with no deaths and recovered vals have shorter lists\n",
    "    '''\n",
    "    for i, row in enumerate(values):\n",
    "        if len(row) < len(header):\n",
    "            extra_zeros = (len(header) - len(row))\n",
    "            values[i] += [0] * extra_zeros\n",
    "\n",
    "    if not values:\n",
    "        print('No data found.')\n",
    "    else:\n",
    "        all_data = []\n",
    "        for col_id, col_name in enumerate(header):\n",
    "            column_data = []\n",
    "            for row in values:\n",
    "                column_data.append(row[col_id])\n",
    "            ds = pd.Series(data=column_data, name=col_name)\n",
    "            all_data.append(ds)\n",
    "        tmp = pd.concat(all_data, axis=1)\n",
    "        \n",
    "    print(sheet_range)\n",
    "    return tmp\n",
    "   \n",
    "df_list = []\n",
    "for sheet_range in cleaned_ranges:\n",
    "    df_list.append(get_data(sheet_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the data we now need to clean it \n",
    "- Fill null values\n",
    "- remore suspected values\n",
    "- change column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(tmp_df):\n",
    "    if 'Demised' in tmp_df.columns:\n",
    "        tmp_df.rename(columns={'Demised':'Deaths'}, inplace=True)\n",
    "\n",
    "    if 'Country/Region' in tmp_df.columns:\n",
    "        tmp_df.rename(columns={'Country/Region':'country'}, inplace=True)\n",
    "    \n",
    "    if 'Province/State' in tmp_df.columns:\n",
    "        tmp_df.rename(columns={'Province/State':'province'}, inplace=True)\n",
    "      \n",
    "    if 'Last Update' in tmp_df.columns:\n",
    "        tmp_df.rename(columns={'Last Update':'date'}, inplace=True)\n",
    "        \n",
    "    if 'Suspected' in tmp_df.columns:\n",
    "        tmp_df = tmp_df.drop(columns='Suspected')\n",
    "\n",
    "    for col in tmp_df.columns:\n",
    "        tmp_df[col] = tmp_df[col].fillna(0)\n",
    "    \n",
    "    #Lower case all col names\n",
    "    tmp_df.columns = map(str.lower, tmp_df.columns)    \n",
    "    \n",
    "    return tmp_df\n",
    "\n",
    "cleaned_dataframes = []\n",
    "for frame in df_list:\n",
    "    cleaned_dataframes.append(clean_data(frame))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute the missing columns in the early stages with 0 values (recovered and deaths)\n",
    "cleaned_dataframes[-1]['recovered'] = [0] * (cleaned_dataframes[-1]).shape[0]\n",
    "cleaned_dataframes[-1]['deaths'] = [0] * (cleaned_dataframes[-1]).shape[0]\n",
    "\n",
    "cleaned_dataframes[-2]['recovered'] = [0] * (cleaned_dataframes[-2]).shape[0]\n",
    "cleaned_dataframes[-2]['deaths'] = [0] * (cleaned_dataframes[-2]).shape[0]\n",
    "\n",
    "final_df = pd.concat(cleaned_dataframes, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confirmed</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>deaths</th>\n",
       "      <th>province</th>\n",
       "      <th>recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Inner Mongolia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Hunan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>444</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Hubei</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   confirmed      country             date deaths        province recovered\n",
       "37         1  South Korea  1/22/2020 12:00      0                         0\n",
       "15         0        China  1/22/2020 12:00      0  Inner Mongolia         0\n",
       "14         4        China  1/22/2020 12:00      0           Hunan         0\n",
       "13       444        China  1/22/2020 12:00      0           Hubei         0\n",
       "12                  China  1/22/2020 12:00      0       Hong Kong         0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['date'] = final_df['date'].astype(str)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './data/updated_{}.parquet.gzip'.format(datetime.date(datetime.now()))\n",
    "final_df.to_parquet(file_name, engine='fastparquet', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_csv = pd.read_csv(file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confirmed</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>deaths</th>\n",
       "      <th>province</th>\n",
       "      <th>recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Inner Mongolia</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hunan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>444.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hubei</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Henan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Heilongjiang</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hebei</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jiangsu</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hainan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Guangxi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Guangdong</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gansu</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fujian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chongqing</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Guizhou</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jiangxi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Liaoning</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zhejiang</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yunnan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Xinjiang</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tibet</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tianjin</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>China</td>\n",
       "      <td>1/22/2020 12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jilin</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>84.0</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fujian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>12.0</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ningxia</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>14.0</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Guizhou</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>4.0</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Finland</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Cambodia</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>5.0</td>\n",
       "      <td>France</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>4.0</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>2.0</td>\n",
       "      <td>US</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>California</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Qinghai</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Macau</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Macau</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jilin</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>3554.0</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/29/2020 14:30</td>\n",
       "      <td>125.0</td>\n",
       "      <td>Hubei</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     confirmed               country             date  deaths  \\\n",
       "0          1.0           South Korea  1/22/2020 12:00     0.0   \n",
       "1          0.0                 China  1/22/2020 12:00     0.0   \n",
       "2          4.0                 China  1/22/2020 12:00     0.0   \n",
       "3        444.0                 China  1/22/2020 12:00     0.0   \n",
       "4          NaN                 China  1/22/2020 12:00     0.0   \n",
       "5          5.0                 China  1/22/2020 12:00     0.0   \n",
       "6          NaN                 China  1/22/2020 12:00     0.0   \n",
       "7          1.0                 China  1/22/2020 12:00     0.0   \n",
       "8          1.0                 China  1/22/2020 12:00     0.0   \n",
       "9          4.0                 China  1/22/2020 12:00     0.0   \n",
       "10         2.0                 China  1/22/2020 12:00     0.0   \n",
       "11        26.0                 China  1/22/2020 12:00     0.0   \n",
       "12         0.0                 China  1/22/2020 12:00     0.0   \n",
       "13         1.0                 China  1/22/2020 12:00     0.0   \n",
       "14         6.0                 China  1/22/2020 12:00     0.0   \n",
       "15        14.0                 China  1/22/2020 12:00     0.0   \n",
       "16         1.0                 China  1/22/2020 12:00     0.0   \n",
       "17         1.0                 China  1/22/2020 12:00     0.0   \n",
       "18         2.0                 China  1/22/2020 12:00     0.0   \n",
       "19         2.0              Thailand  1/22/2020 12:00     0.0   \n",
       "20         2.0                 China  1/22/2020 12:00     0.0   \n",
       "21         2.0                 Japan  1/22/2020 12:00     0.0   \n",
       "22        10.0                 China  1/22/2020 12:00     0.0   \n",
       "23         1.0                 China  1/22/2020 12:00     0.0   \n",
       "24         0.0                 China  1/22/2020 12:00     0.0   \n",
       "25         1.0                    US  1/22/2020 12:00     0.0   \n",
       "26         0.0                 China  1/22/2020 12:00     0.0   \n",
       "27         4.0                 China  1/22/2020 12:00     0.0   \n",
       "28         1.0                 China  1/22/2020 12:00     0.0   \n",
       "29         NaN                 China  1/22/2020 12:00     0.0   \n",
       "..         ...                   ...              ...     ...   \n",
       "344       84.0        Mainland China  1/29/2020 14:30     0.0   \n",
       "345       12.0        Mainland China  1/29/2020 14:30     0.0   \n",
       "346       14.0              Thailand  1/29/2020 14:30     NaN   \n",
       "347        9.0        Mainland China  1/29/2020 14:30     NaN   \n",
       "348        4.0  United Arab Emirates  1/29/2020 14:30     0.0   \n",
       "349        1.0               Finland  1/29/2020 14:30     0.0   \n",
       "350        4.0               Germany  1/29/2020 14:30     0.0   \n",
       "351        1.0             Australia  1/29/2020 14:30     0.0   \n",
       "352        4.0             Australia  1/29/2020 14:30     0.0   \n",
       "353        1.0             Sri Lanka  1/29/2020 14:30     0.0   \n",
       "354        1.0              Cambodia  1/29/2020 14:30     0.0   \n",
       "355        1.0                Canada  1/29/2020 14:30     0.0   \n",
       "356        1.0                Canada  1/29/2020 14:30     0.0   \n",
       "357        7.0              Malaysia  1/29/2020 14:30     0.0   \n",
       "358        1.0                 Nepal  1/29/2020 14:30     0.0   \n",
       "359       10.0             Hong Kong  1/29/2020 14:30     0.0   \n",
       "360        5.0                France  1/29/2020 14:30     0.0   \n",
       "361        7.0             Singapore  1/29/2020 14:30     0.0   \n",
       "362        4.0           South Korea  1/29/2020 14:30     0.0   \n",
       "363        7.0                 Japan  1/29/2020 14:30     NaN   \n",
       "364        1.0                    US  1/29/2020 14:30     0.0   \n",
       "365        2.0                    US  1/29/2020 14:30     0.0   \n",
       "366        1.0                    US  1/29/2020 14:30     0.0   \n",
       "367        1.0                    US  1/29/2020 14:30     0.0   \n",
       "368        6.0        Mainland China  1/29/2020 14:30     0.0   \n",
       "369        7.0                 Macau  1/29/2020 14:30     0.0   \n",
       "370        8.0                Taiwan  1/29/2020 14:30     0.0   \n",
       "371        9.0        Mainland China  1/29/2020 14:30     0.0   \n",
       "372        2.0               Vietnam  1/29/2020 14:30     0.0   \n",
       "373     3554.0        Mainland China  1/29/2020 14:30   125.0   \n",
       "\n",
       "             province  recovered  \n",
       "0                 NaN        0.0  \n",
       "1      Inner Mongolia        0.0  \n",
       "2               Hunan        0.0  \n",
       "3               Hubei        0.0  \n",
       "4           Hong Kong        0.0  \n",
       "5               Henan        0.0  \n",
       "6        Heilongjiang        0.0  \n",
       "7               Hebei        0.0  \n",
       "8             Jiangsu        0.0  \n",
       "9              Hainan        0.0  \n",
       "10            Guangxi        0.0  \n",
       "11          Guangdong        0.0  \n",
       "12              Gansu        0.0  \n",
       "13             Fujian        0.0  \n",
       "14          Chongqing        0.0  \n",
       "15            Beijing        0.0  \n",
       "16              Anhui        0.0  \n",
       "17            Guizhou        0.0  \n",
       "18            Jiangxi        0.0  \n",
       "19                NaN        0.0  \n",
       "20           Liaoning        0.0  \n",
       "21                NaN        0.0  \n",
       "22           Zhejiang        0.0  \n",
       "23             Yunnan        0.0  \n",
       "24           Xinjiang        0.0  \n",
       "25         Washington        0.0  \n",
       "26              Tibet        0.0  \n",
       "27            Tianjin        0.0  \n",
       "28             Taiwan        0.0  \n",
       "29              Jilin        0.0  \n",
       "..                ...        ...  \n",
       "344            Fujian        0.0  \n",
       "345           Ningxia        0.0  \n",
       "346               NaN        5.0  \n",
       "347           Guizhou        1.0  \n",
       "348               NaN        0.0  \n",
       "349               NaN        0.0  \n",
       "350           Bavaria        0.0  \n",
       "351          Victoria        0.0  \n",
       "352   New South Wales        0.0  \n",
       "353               NaN        0.0  \n",
       "354               NaN        0.0  \n",
       "355  British Columbia        0.0  \n",
       "356           Ontario        0.0  \n",
       "357               NaN        0.0  \n",
       "358               NaN        0.0  \n",
       "359         Hong Kong        0.0  \n",
       "360               NaN        0.0  \n",
       "361               NaN        0.0  \n",
       "362               NaN        0.0  \n",
       "363               NaN        1.0  \n",
       "364           Arizona        0.0  \n",
       "365        California        0.0  \n",
       "366          Illinois        0.0  \n",
       "367        Washington        0.0  \n",
       "368           Qinghai        0.0  \n",
       "369             Macau        0.0  \n",
       "370            Taiwan        0.0  \n",
       "371             Jilin        0.0  \n",
       "372               NaN        0.0  \n",
       "373             Hubei       88.0  \n",
       "\n",
       "[374 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python36864bitanaconda3virtualenv59e2ff4492e04649af7e0fd703909eac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
